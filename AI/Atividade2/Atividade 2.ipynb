{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praticando o Pré-processamento para trabalhar com modelos de Máquina de Aprendizagem.\n",
    "\n",
    "Dataset escolhido: 93182_steam_games.csv\n",
    "\n",
    "Link: https://www.kaggle.com/datasets/joebeachcapital/top-1000-steam-games/data\n",
    "\n",
    "Descrição do dataset: 93182 Games from Steam and SteamSpy as of September 15, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Leitura de um dataset\n",
    "\n",
    "Objetivo: Ler e exibir informações básicas de um dataset.\n",
    "- **Passo 1**: Baixe um dataset em formato ```.csv``` ou ```.xlsx```\n",
    "- **Passo 2**: Exiba as primeiras 10 linhas do dataset utilizando ```df.head()```.\n",
    "- **Passo 3**: Exiba informações gerais sobre o dataset (número de linhas, colunas, tipos de dados, valores nulos) com ```df.info()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AppID                                    Name  Release date  \\\n",
      "0  1424640                                      余烬   Oct 3, 2020   \n",
      "1   402890                             Nyctophilia  Sep 23, 2015   \n",
      "2  1151740                         Prison Princess   Apr 2, 2020   \n",
      "3   875530                            Dead In Time  Oct 12, 2018   \n",
      "4  1835360                   Panacle: Back To Wild  Mar 11, 2022   \n",
      "5   431510  Mystic Destinies: Serendipity of Aeons  Feb 11, 2016   \n",
      "6  1054250                            krAsAvA Shot   Apr 4, 2019   \n",
      "7  2604580                             THE JUSOU 3  Feb 20, 2024   \n",
      "8  1154840                           Shadow Empire   Dec 3, 2020   \n",
      "9   496740                     Discovering Space 2  Mar 10, 2017   \n",
      "\n",
      "  Estimated owners  Peak CCU  Required age  Price  DLC count  \\\n",
      "0    20000 - 50000         0             0   3.99          0   \n",
      "1   50000 - 100000         0             0   0.00          0   \n",
      "2        0 - 20000         0             0  19.99          0   \n",
      "3        0 - 20000         0             0   7.99          0   \n",
      "4        0 - 20000         2             0   3.99          0   \n",
      "5  100000 - 200000         1             0   0.00         11   \n",
      "6        0 - 20000         0             0   0.99          0   \n",
      "7        0 - 20000         1             0   9.99          0   \n",
      "8   50000 - 100000        83             0  39.99          1   \n",
      "9        0 - 20000         0             0   9.99          0   \n",
      "\n",
      "                                      About the game  \\\n",
      "0  'Ashes of war' is an anti war theme adventure ...   \n",
      "1  NYCTOPHILIA Nyctophilia is an 2D psychological...   \n",
      "2  ABOUT Now nothing more than a phantom, can the...   \n",
      "3  Is a hardcore action with a non-trivial level ...   \n",
      "4  Panacle: Back to the Wild is a indie card game...   \n",
      "5  MDSOA is now 100% complete! You can purchase t...   \n",
      "6  2079 planet Earth. Together with the spacecraf...   \n",
      "7  ■ The Ultimate Horror Escape Game 'THE JUSOU -...   \n",
      "8  Shadow Empire is a deep turn-based 4X wargame ...   \n",
      "9  A breath-taking space exploration experience i...   \n",
      "\n",
      "                                 Supported languages  ...  \\\n",
      "0                             ['Simplified Chinese']  ...   \n",
      "1                             ['English', 'Russian']  ...   \n",
      "2  ['English', 'Simplified Chinese', 'Traditional...  ...   \n",
      "3                             ['English', 'Russian']  ...   \n",
      "4  ['English', 'Japanese', 'Simplified Chinese', ...  ...   \n",
      "5                                        ['English']  ...   \n",
      "6                             ['English', 'Russian']  ...   \n",
      "7  ['Japanese', 'English', 'Simplified Chinese', ...  ...   \n",
      "8                                        ['English']  ...   \n",
      "9                                        ['English']  ...   \n",
      "\n",
      "  Average playtime two weeks Median playtime forever  \\\n",
      "0                          0                       0   \n",
      "1                          0                       0   \n",
      "2                          0                       0   \n",
      "3                          0                       0   \n",
      "4                          0                       0   \n",
      "5                          0                       0   \n",
      "6                          0                       0   \n",
      "7                          0                       0   \n",
      "8                          0                       0   \n",
      "9                          0                       0   \n",
      "\n",
      "  Median playtime two weeks          Developers          Publishers  \\\n",
      "0                         0       宁夏华夏西部影视城有限公司       宁夏华夏西部影视城有限公司   \n",
      "1                         0  Cat In A Jar Games  Cat In A Jar Games   \n",
      "2                         0             qureate             qureate   \n",
      "3                         0       Zelenov Artem       Zelenov Artem   \n",
      "4                         0                渡鸦游戏            渡鸦游戏,电钮组   \n",
      "5                         0  Aeon Dream Studios  Aeon Dream Studios   \n",
      "6                         0       MIGALOO GAMES       MIGALOO GAMES   \n",
      "7                         0        株式会社Metaware        株式会社Metaware   \n",
      "8                         0          VR Designs     Slitherine Ltd.   \n",
      "9                         0      Discovering VR      Discovering VR   \n",
      "\n",
      "                                          Categories  \\\n",
      "0                       Single-player,Family Sharing   \n",
      "1                                      Single-player   \n",
      "2  Single-player,Steam Achievements,Full controll...   \n",
      "3  Single-player,Full controller support,Family S...   \n",
      "4                       Single-player,Family Sharing   \n",
      "5  Single-player,Steam Achievements,Steam Trading...   \n",
      "6  Single-player,Multi-player,Co-op,Online Co-op,...   \n",
      "7                       Single-player,Family Sharing   \n",
      "8  Single-player,Multi-player,PvP,Shared/Split Sc...   \n",
      "9  Single-player,Tracked Controller Support,VR On...   \n",
      "\n",
      "                              Genres  \\\n",
      "0         Adventure,Casual,Indie,RPG   \n",
      "1       Adventure,Free To Play,Indie   \n",
      "2                    Adventure,Indie   \n",
      "3                       Action,Indie   \n",
      "4        Indie,Strategy,Early Access   \n",
      "5  Adventure,Casual,Indie,Simulation   \n",
      "6                    Adventure,Indie   \n",
      "7             Adventure,Casual,Indie   \n",
      "8            RPG,Simulation,Strategy   \n",
      "9            Casual,Indie,Simulation   \n",
      "\n",
      "                                                Tags  \\\n",
      "0  Sokoban,RPG,Puzzle-Platformer,Exploration,Adve...   \n",
      "1  Free to Play,Indie,Adventure,Horror,2D,Pixel G...   \n",
      "2  Sexual Content,Adventure,Indie,Nudity,Anime,Ma...   \n",
      "3  Action,Indie,Souls-like,Fantasy,Early Access,R...   \n",
      "4  Trading Card Game,Turn-Based Strategy,Lore-Ric...   \n",
      "5  Visual Novel,Otome,Female Protagonist,Indie,Fr...   \n",
      "6                               Indie,Gore,Adventure   \n",
      "7  Exploration,Puzzle,Female Protagonist,2D,3D,Ho...   \n",
      "8  Strategy,Simulation,4X,RPG,Wargame,Turn-Based ...   \n",
      "9                   Casual,Simulation,Indie,VR,Space   \n",
      "\n",
      "                                         Screenshots  \\\n",
      "0  https://shared.akamai.steamstatic.com/store_it...   \n",
      "1  https://shared.akamai.steamstatic.com/store_it...   \n",
      "2  https://shared.akamai.steamstatic.com/store_it...   \n",
      "3  https://shared.akamai.steamstatic.com/store_it...   \n",
      "4  https://shared.akamai.steamstatic.com/store_it...   \n",
      "5  https://shared.akamai.steamstatic.com/store_it...   \n",
      "6  https://shared.akamai.steamstatic.com/store_it...   \n",
      "7  https://shared.akamai.steamstatic.com/store_it...   \n",
      "8  https://shared.akamai.steamstatic.com/store_it...   \n",
      "9  https://shared.akamai.steamstatic.com/store_it...   \n",
      "\n",
      "                                              Movies  \n",
      "0  http://video.akamai.steamstatic.com/store_trai...  \n",
      "1  http://video.akamai.steamstatic.com/store_trai...  \n",
      "2  http://video.akamai.steamstatic.com/store_trai...  \n",
      "3  http://video.akamai.steamstatic.com/store_trai...  \n",
      "4  http://video.akamai.steamstatic.com/store_trai...  \n",
      "5  http://video.akamai.steamstatic.com/store_trai...  \n",
      "6  http://video.akamai.steamstatic.com/store_trai...  \n",
      "7  http://video.akamai.steamstatic.com/store_trai...  \n",
      "8  http://video.akamai.steamstatic.com/store_trai...  \n",
      "9  http://video.akamai.steamstatic.com/store_trai...  \n",
      "\n",
      "[10 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the path for the csv file\n",
    "file_path = '../../dataset/93182_steam_games.csv'\n",
    "\n",
    "# Read the csv data into the data frame\n",
    "df = pd.read_csv(file_path, dtype={'Estimated owners': str, 'Tags': str})\n",
    "# Show the first 10 lines from the data frame \n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Limpeza de Dados: Remoção de Valores Faltantes\n",
    "\n",
    "Objetivo: Tratar dados ausentes.\n",
    "- **Passo 1**: Identifique as colunas que contêm valores nulos (NaN).\n",
    "- **Passo 2**: Remova ou preencha os valores nulos com a média, mediana ou moda, dependendo do tipo da variável (numérica ou categórica).\n",
    "    - Para variáveis numéricas: substitua valores nulos pela média ou mediana.\n",
    "    - Para variáveis categóricas: substitua os valores nulos pela moda (valor mais frequente).\n",
    "- **Passo 3**: Após o tratamento, verifique se os valores nulos foram realmente removidos ou substituidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null columns\n",
    "null_columns = df.isnull().any()\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define strategie to impute falty data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[[\n",
    "    'Score rank'\n",
    "]] = imputer.fit_transform(df[['Score rank']])\n",
    "\n",
    "# Drop columns that don't won't be used for now\n",
    "df_cleaned = df.drop([\n",
    "    'Estimated owners', \n",
    "    'Reviews', \n",
    "    'Support url', \n",
    "    'Support email',\n",
    "    'Metacritic url',\n",
    "    'Score rank',\n",
    "    'Notes',\n",
    "    'Tags',\n",
    "    'Screenshots',\n",
    "    'Movies',\n",
    "    'Average playtime forever',\n",
    "    'Average playtime two weeks',\n",
    "    'Median playtime forever',\n",
    "    'Median playtime two weeks'\n",
    "    ], axis=1)\n",
    "\n",
    "# Drop rows that have null values\n",
    "df_cleaned = df_cleaned.dropna(subset=[\n",
    "    'Name', \n",
    "    'Developers', \n",
    "    'Publishers', \n",
    "    'Categories',\n",
    "    'Genres'\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if there's null data on the columns after cleaning\n",
    "null_columns = df_cleaned.isnull().any()\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversão de tipo de dados\n",
    "\n",
    "Objetivo: Corrigir tipos de dados incorretos.\n",
    "- **Passo 1**: Verifique o tipo de cada coluna utilizando ```df.dtypes```.\n",
    "- **Passo 2**: Converta colunas de tipo errado (por exemplo, uma coluna numérica que foi lida como string) para o tipo correto.\n",
    "    - Exemplo: Converta uma coluna de idade de string para inteiro.\n",
    "- **Passo 3**: Verifique novamente os tipos de dados para garantir que a conversão foi feita corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns\n",
    "df_converted = df_cleaned.convert_dtypes()\n",
    "\n",
    "print(df_converted.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remoção de duplicatas\n",
    "\n",
    "Objetivo: Eliminar entradas duplicadas.\n",
    "- **Passo 1**: Identifique se há registros duplicados usando ```df.duplicated()```.\n",
    "- **Passo 2**: Remova os registros duplicados com ```df.drop_duplicates()``` e verifique se o número de linhas diminuiu.\n",
    "- **Passo 3**: Verifique novamente o dataset para garantir que as duplicatas foram removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify existence of duplicate rows\n",
    "print(df_converted.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping duplicate rows\n",
    "df_converted.drop_duplicates()\n",
    "\n",
    "# Verifying if the duplicated rows were droped\n",
    "print(df_converted.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length stayed the same before and after droping duplicates, implying that there were no duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalização e padronização de dados\n",
    "\n",
    "Objetivo: Aplicar técnicas de normalização e padronização.\n",
    "- **Passo 1**: Selecione colunas numéricas do dataset.\n",
    "- **Passo 2**: Realize a **normalização** (scaling) das variáveis numéricas, onde os valores estarão entre 0 e 1 (pode usar o ```MinMaxScaler``` do Scikit-learn).\n",
    "- **Passo 3**: Realize a **padronização**, onde os valores terão média 0 e desvio padrão 1 (pode usar o ```StandardScaler``` do Scikit-learn).\n",
    "- **Passo 4**: Compare os resultados antes e depois da normalização/padronização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(df_converted.head())\n",
    "\n",
    "\n",
    "columns_to_scale = [\n",
    "    'Peak CCU',\n",
    "    'Required age',\n",
    "    'Price',\n",
    "    'DLC count',\n",
    "    'Metacritic score',\n",
    "    'User score',\n",
    "    'Positive',\n",
    "    'Negative',\n",
    "    'Achievements',\n",
    "    'Recommendations'\n",
    "]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#df_converted = df_converted.sample(n = 5000, random_state=42)\n",
    "df_converted[columns_to_scale] = scaler.fit_transform(df_converted[columns_to_scale])\n",
    "\n",
    "#pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.float_format = None\n",
    "\n",
    "print(df_converted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Criação de variáveis categóricas (Encoding)\n",
    "\n",
    "Objetivo: Converter variáveis categóricas em variáveis numéricas.\n",
    "- **Passo 1**: Identifique variáveis categóricas\n",
    "- **Passo 2**: Aplique a codificação usando uma técnica como **One-Hot Encoding** ou **Label Encoding**.\n",
    "    - Use ```pd.get_dummies()``` para One-Hot Encoding.\n",
    "    - Use ```LabelEncoder``` do Scikit-learn para Label Encoding.\n",
    "- **Passo 3**: Verifique se as variáveis categóricas foram corretamente convertidas para numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Sample your data\n",
    "df_encoded = df_converted.copy()#.sample(n=5000, random_state=42)\n",
    "\n",
    "# Columns to encode\n",
    "multi_label_columns = ['Supported languages', 'Full audio languages', 'Categories', 'Genres']\n",
    "\n",
    "# Updated function handles list, string, np.nan, np.ndarray, etc.\n",
    "def clean_multilabel(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        flat = []\n",
    "        for item in x:\n",
    "            flat.extend([s.strip() for s in str(item).split(',') if s.strip()])\n",
    "        return flat\n",
    "    else:\n",
    "        return [s.strip() for s in str(x).split(',') if s.strip()]\n",
    "\n",
    "# Apply encoding\n",
    "for col in multi_label_columns:\n",
    "    df_encoded[col] = df_encoded[col].apply(clean_multilabel)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    encoded = pd.DataFrame(\n",
    "        mlb.fit_transform(df_encoded[col]),\n",
    "        columns=[f\"{col}_{cls}\" for cls in mlb.classes_],\n",
    "        index=df_encoded.index\n",
    "    )\n",
    "\n",
    "    df_encoded = pd.concat([df_encoded.drop(columns=[col]), encoded], axis=1)\n",
    "\n",
    "# Check success\n",
    "print([col for col in df_encoded.columns if col.startswith('Genres_')])\n",
    "print(df_encoded)\n",
    "print(df_encoded.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Detecção e Tratamento de Outliers\n",
    "\n",
    "Objetivo: Identificar e tratar outliers.\n",
    "- **Passo 1**: Calcule o **intervalo interquartil (IQR)** para identificar os outliers.\n",
    "- **Passo 2**: Identifique os pontos fora do intervalo (valores menores que ```Q1 - 1.5*IQR``` ou maiores que ```Q3 + 1.5*IQR```).\n",
    "- **Passo 3**: Remova ou substitua os outliers idetificados.\n",
    "- **Passo 4**: Verifique se os outliers foram eliminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas numéricas (sem one-hot)\n",
    "columns_to_check = [\n",
    "    'Peak CCU',\n",
    "    'Price',\n",
    "    'DLC count',\n",
    "    'Metacritic score',\n",
    "    'User score',\n",
    "    'Positive',\n",
    "    'Negative',\n",
    "    'Achievements',\n",
    "    'Recommendations'\n",
    "]\n",
    "\n",
    "def treat_outliers_iqr(df, columns, method='remove'):\n",
    "    \"\"\"\n",
    "    Detect and treat outliers using IQR method on selected columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        columns (list): List of column names to check for outliers\n",
    "        method (str): 'remove' to drop rows with outliers, 'replace' to replace with median\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    outlier_mask = pd.DataFrame(False, index=df_copy.index, columns=columns)\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        mask = (df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)\n",
    "        outlier_mask[col] = mask\n",
    "\n",
    "        if method == 'replace':\n",
    "            median = df_copy[col].median()\n",
    "            df_copy.loc[mask, col] = median\n",
    "\n",
    "    if method == 'remove':\n",
    "        rows_with_outliers = outlier_mask.any(axis=1)\n",
    "        df_copy = df_copy[~rows_with_outliers].copy()\n",
    "\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = treat_outliers_iqr(df_encoded, columns_to_check, method='remove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check if any outliers remain\n",
    "def count_outliers_iqr(df, columns):\n",
    "    outlier_counts = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outlier_counts[col] = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "    return outlier_counts\n",
    "\n",
    "print(count_outliers_iqr(df_no_outliers, columns_to_check))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Transformação de Variáveis (Log Transform)\n",
    "\n",
    "Objetivo: Aplicar transformações logarítmicas para variáveis altamente assimétricas.\n",
    "- **Passo 1**: Visualize a distribuição de algumas variáveis (use ```sns.histplot()``` ou ```df.hist()```).\n",
    "- **Passo 2**: Aplique uma transformação logarítmica nas variáveis com distribuição assimétrica (utilize ```np.log()```).\n",
    "- **Passo 3**: Visualize novamente a distribuição após a transformação e compare os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(data=df_no_outliers, x='Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = df_no_outliers.skew(numeric_only=True)\n",
    "skewed_cols = skewed_cols[skewed_cols.abs() > 1].index\n",
    "\n",
    "df_log_transformed = df_no_outliers.copy()\n",
    "df_log_transformed[skewed_cols] = np.log1p(df_log_transformed[skewed_cols])\n",
    "\n",
    "for col in skewed_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df_log_transformed[col], bins=30, kde=True)\n",
    "    plt.title(f\"Distribuição após log: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
